{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c38793e-dcca-465a-837f-d0412bb4d776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate==0.29.1\n",
      "bitsandbytes==0.43.0\n",
      "datasets==2.18.0\n",
      "einops==0.7.0\n",
      "fsspec==2023.10.0\n",
      "peft @ git+https://github.com/huggingface/peft.git@e07095a654fa72835651e6e0ad846fc6f517baa9\n",
      "torch==1.12.1\n",
      "transformers==4.37.2\n",
      "trl==0.8.1\n",
      "wandb==0.16.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze | grep -E \"torch|fsspec|trl|transformers|bitsandbytes|datasets|accelerate|peft|einops|wandb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1754fa4b-e8fd-425b-bc92-eebbbf58ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec==2023.10.0\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2023.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fsspec==2023.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88c6ace-d368-4a37-ba67-625b2a7600cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.2.2\n",
      "Uninstalling torch-2.2.2:\n",
      "  Successfully uninstalled torch-2.2.2\n",
      "Found existing installation: fsspec 2023.10.0\n",
      "Uninstalling fsspec-2023.10.0:\n",
      "  Successfully uninstalled fsspec-2023.10.0\n",
      "Found existing installation: trl 0.8.1\n",
      "Uninstalling trl-0.8.1:\n",
      "  Successfully uninstalled trl-0.8.1\n",
      "Found existing installation: transformers 4.39.3\n",
      "Uninstalling transformers-4.39.3:\n",
      "  Successfully uninstalled transformers-4.39.3\n",
      "Found existing installation: bitsandbytes 0.43.0\n",
      "Uninstalling bitsandbytes-0.43.0:\n",
      "  Successfully uninstalled bitsandbytes-0.43.0\n",
      "Found existing installation: datasets 2.18.0\n",
      "Uninstalling datasets-2.18.0:\n",
      "  Successfully uninstalled datasets-2.18.0\n",
      "Found existing installation: accelerate 0.29.1\n",
      "Uninstalling accelerate-0.29.1:\n",
      "  Successfully uninstalled accelerate-0.29.1\n",
      "Found existing installation: peft 0.10.1.dev0\n",
      "Uninstalling peft-0.10.1.dev0:\n",
      "  Successfully uninstalled peft-0.10.1.dev0\n",
      "Found existing installation: einops 0.7.0\n",
      "Uninstalling einops-0.7.0:\n",
      "  Successfully uninstalled einops-0.7.0\n",
      "Found existing installation: wandb 0.16.6\n",
      "Uninstalling wandb-0.16.6:\n",
      "  Successfully uninstalled wandb-0.16.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall torch fsspec trl transformers bitsandbytes datasets accelerate peft einops wandb --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7216d877-9b0c-480b-8a94-7ed4a719ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2.0\n",
      "  Downloading torch-2.2.0-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (1.12)\n",
      "Requirement already satisfied: networkx in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from torch==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./myenv-test002-03/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from jinja2->torch==2.2.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv-test002-03/lib/python3.9/site-packages (from sympy->torch==2.2.0) (1.3.0)\n",
      "Downloading torch-2.2.0-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m524.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:27\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "Successfully installed torch-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369ad88c-738b-4fe8-8210-62b719084116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./myenv-test002-02/lib/python3.9/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./myenv-test002-02/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv-test002-02/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv-test002-02/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d56b402-5aa2-435a-bb26-d53d5d6adef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.2.2\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/cv/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
      "Required-by: accelerate, bitsandbytes, peft, trl\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303314f6-a748-4a57-831e-376d208044ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-o8v4n4pm\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-o8v4n4pm\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 31c884e93469dd1391bb54eb1468311c38bbccac\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: trl in ./myenv-test002-03/lib/python3.9/site-packages (0.8.1)\n",
      "Requirement already satisfied: transformers in ./myenv-test002-03/lib/python3.9/site-packages (4.37.2)\n",
      "Requirement already satisfied: accelerate in ./myenv-test002-03/lib/python3.9/site-packages (0.29.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in ./myenv-test002-03/lib/python3.9/site-packages (from trl) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in ./myenv-test002-03/lib/python3.9/site-packages (from trl) (1.26.4)\n",
      "Requirement already satisfied: datasets in ./myenv-test002-03/lib/python3.9/site-packages (from trl) (2.18.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in ./myenv-test002-03/lib/python3.9/site-packages (from trl) (0.8.2)\n",
      "Requirement already satisfied: filelock in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./myenv-test002-03/lib/python3.9/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in ./myenv-test002-03/lib/python3.9/site-packages (from accelerate) (5.9.8)\n",
      "Collecting torch>=1.4.0 (from trl)\n",
      "  Using cached torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv-test002-03/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv-test002-03/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from torch>=1.4.0->trl) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./myenv-test002-03/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in ./myenv-test002-03/lib/python3.9/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in ./myenv-test002-03/lib/python3.9/site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in ./myenv-test002-03/lib/python3.9/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: eval-type-backport>=0.1.3 in ./myenv-test002-03/lib/python3.9/site-packages (from tyro>=0.5.11->trl) (0.1.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets->trl) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./myenv-test002-03/lib/python3.9/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./myenv-test002-03/lib/python3.9/site-packages (from datasets->trl) (2.2.1)\n",
      "Requirement already satisfied: xxhash in ./myenv-test002-03/lib/python3.9/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./myenv-test002-03/lib/python3.9/site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in ./myenv-test002-03/lib/python3.9/site-packages (from datasets->trl) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv-test002-03/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv-test002-03/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv-test002-03/lib/python3.9/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv-test002-03/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv-test002-03/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv-test002-03/lib/python3.9/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv-test002-03/lib/python3.9/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv-test002-03/lib/python3.9/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv-test002-03/lib/python3.9/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./myenv-test002-03/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv-test002-03/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Using cached torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed torch-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trl transformers accelerate git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa1844a-a6fe-4de7-91fc-23504fb50b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./myenv-test002-03/lib/python3.9/site-packages (2.18.0)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting einops\n",
      "  Using cached einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting wandb\n",
      "  Using cached wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in ./myenv-test002-03/lib/python3.9/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv-test002-03/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: torch in ./myenv-test002-03/lib/python3.9/site-packages (from bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (1.44.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (58.1.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (4.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in ./myenv-test002-03/lib/python3.9/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: six>=1.4.0 in ./myenv-test002-03/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./myenv-test002-03/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./myenv-test002-03/lib/python3.9/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv-test002-03/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv-test002-03/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv-test002-03/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv-test002-03/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv-test002-03/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv-test002-03/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv-test002-03/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: sympy in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./myenv-test002-03/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./myenv-test002-03/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv-test002-03/lib/python3.9/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Using cached bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
      "Using cached einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Using cached wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
      "Installing collected packages: einops, wandb, bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.0 einops-0.7.0 wandb-0.16.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U datasets bitsandbytes einops wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2329e704-d49a-4864-8d86-6e6ce8d3d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./myenv-test002-02/lib/python3.9/site-packages (22.0.4)\n",
      "Collecting pip\n",
      "  Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.4\n",
      "    Uninstalling pip-22.0.4:\n",
      "      Successfully uninstalled pip-22.0.4\n",
      "Successfully installed pip-24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77d6a33e-9583-4c91-b3fb-51850a9b786b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468801c433194300a15777a107f7a02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/395 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc86e463408416da049c702a32ae41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc48866a266147a7beb7e4604d66b440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4d37418e42489da44ba3eec3cbf5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb07bac88eee44faaf9b0e4d2e8afe91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary library for loading datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Specify the name of the dataset\n",
    "dataset_name = \"timdettmers/openassistant-guanaco\"\n",
    "\n",
    "# Load the dataset from the specified name and select the \"train\" split\n",
    "dataset = load_dataset(dataset_name, split=\"train\", download_mode=\"force_redownload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ecf8cf-7d65-4783-8c17-bbcc01ea83de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia_cublas_cu11 in ./myenv-test002-03/lib/python3.9/site-packages (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in ./myenv-test002-03/lib/python3.9/site-packages (from nvidia_cublas_cu11) (58.1.0)\n",
      "Requirement already satisfied: wheel in ./myenv-test002-03/lib/python3.9/site-packages (from nvidia_cublas_cu11) (0.43.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nvidia_cublas_cu11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dada03ea-979f-455f-a76b-73aeb132706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: nvidia-cublas-cu11 11.10.3.66\n",
      "Uninstalling nvidia-cublas-cu11-11.10.3.66:\n",
      "  Successfully uninstalled nvidia-cublas-cu11-11.10.3.66\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall nvidia_cublas_cu11 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ea9d80-4cf0-4998-b131-8bef5772325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in ./myenv-test002-03/lib/python3.9/site-packages (0.43.0)\n",
      "Requirement already satisfied: torch in ./myenv-test002-03/lib/python3.9/site-packages (from bitsandbytes) (2.2.2)\n",
      "Requirement already satisfied: numpy in ./myenv-test002-03/lib/python3.9/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: sympy in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from torch->bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./myenv-test002-03/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv-test002-03/lib/python3.9/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv-test002-03/lib/python3.9/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcd58e2-ec15-4eeb-b081-1a1634971e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('/org/gnome/Terminal/screen/c3e1568e_c437_4448_a440_948ba9a464bf')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('unix'), PosixPath('path=/run/user/1000/bus,guid=5d0ded17381c572379615cb2660f9aaf')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('1'), PosixPath('0')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('/etc/xdg/xdg-ubuntu')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('local/cv'), PosixPath('@/tmp/.ICE-unix/1029,unix/cv')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "DEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}\n",
      "CUDA SETUP: CUDA version lower than 11 are currently not supported for LLM.int8(). You will be only to use 8-bit optimizers and quantization routines!!\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=102, Highest Compute Capability: 6.1.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Required library version not found: libbitsandbytes_cuda102_nocublaslt.so. Maybe you need to compile it from source?\n",
      "CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...\n",
      "\n",
      "================================================ERROR=====================================\n",
      "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
      "1. You need to manually override the PyTorch CUDA version. Please see: \"https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "2. CUDA driver not installed\n",
      "3. CUDA not installed\n",
      "4. You have multiple conflicting CUDA libraries\n",
      "5. Required library not pre-compiled for this bitsandbytes release!\n",
      "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=118`.\n",
      "CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.\n",
      "================================================================================\n",
      "\n",
      "CUDA SETUP: Something unexpected happened. Please compile from source:\n",
      "git clone https://github.com/TimDettmers/bitsandbytes.git\n",
      "cd bitsandbytes\n",
      "CUDA_VERSION=102_nomatmul\n",
      "python setup.py install\n",
      "CUDA SETUP: Setup Failed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cv/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:183: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n",
      "/home/cv/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:183: UserWarning: /home/cv/anaconda3 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0', 'libcudart.so.12.1', 'libcudart.so.12.2'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/cv/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:183: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0', 'libcudart.so.12.1', 'libcudart.so.12.2'] files: {PosixPath('/usr/local/cuda-11.3/lib64/libcudart.so'), PosixPath('/usr/local/cuda-11.3/lib64/libcudart.so.11.0')}.. We select the PyTorch default libcudart.so, which is {torch.version.cuda},but this might mismatch with the CUDA version that is needed for bitsandbytes.To override this behavior set the BNB_CUDA_VERSION=<version string, e.g. 122> environmental variableFor example, if you want to use the CUDA version 122BNB_CUDA_VERSION=122 python ...OR set the environmental variable in your .bashrc: export BNB_CUDA_VERSION=122In the case of a manual override, make sure you set the LD_LIBRARY_PATH, e.g.export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-12.2\n",
      "  warn(msg)\n",
      "/home/cv/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:183: UserWarning: /usr/local/cuda-11.3/lib64: did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0', 'libcudart.so.12.1', 'libcudart.so.12.2'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/cv/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:183: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0', 'libcudart.so.12.1', 'libcudart.so.12.2'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We select the PyTorch default libcudart.so, which is {torch.version.cuda},but this might mismatch with the CUDA version that is needed for bitsandbytes.To override this behavior set the BNB_CUDA_VERSION=<version string, e.g. 122> environmental variableFor example, if you want to use the CUDA version 122BNB_CUDA_VERSION=122 python ...OR set the environmental variable in your .bashrc: export BNB_CUDA_VERSION=122In the case of a manual override, make sure you set the LD_LIBRARY_PATH, e.g.export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-12.2\n",
      "  warn(msg)\n",
      "/home/cv/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:183: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!                     If you run into issues with 8-bit matmul, you can try 4-bit quantization: https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/transformers/utils/import_utils.py:1364\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/transformers/integrations/bitsandbytes.py:11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_available():\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, research, utils\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MatmulLtState,\n\u001b[1;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     mm_cublas,\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/research/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     matmul_fp8_global,\n\u001b[1;32m      4\u001b[0m     matmul_fp8_mixed,\n\u001b[1;32m      5\u001b[0m     switchback_bnb,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/research/autograd/_functions.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalOutlierPooler, MatmulLtState\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/autograd/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_inverse_transform_indices, undo_layout\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# math.prod not compatible with python < 3.8\u001b[39;00m\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/functional.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pack_dict_to_tensor, unpack_tensor_to_dict\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA, lib\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# math.prod not compatible with python < 3.8\u001b[39;00m\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/bitsandbytes/cextension.py:17\u001b[0m\n\u001b[1;32m     16\u001b[0m     CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mprint_log_stack()\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m    python -m bitsandbytes\u001b[39m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[1;32m     25\u001b[0m _ \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mcadam32bit_grad_fp32  \u001b[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m     11\u001b[0m load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Loading the Falcon model with quantization configuration\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Disabling cache usage in the model configuration\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/transformers/modeling_utils.py:3608\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3605\u001b[0m     keep_in_fp32_modules \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m load_in_4bit:\n\u001b[0;32m-> 3608\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_keys_to_not_convert, replace_with_bnb_linear\n\u001b[1;32m   3610\u001b[0m     llm_int8_skip_modules \u001b[38;5;241m=\u001b[39m quantization_config\u001b[38;5;241m.\u001b[39mllm_int8_skip_modules\n\u001b[1;32m   3611\u001b[0m     load_in_8bit_fp32_cpu_offload \u001b[38;5;241m=\u001b[39m quantization_config\u001b[38;5;241m.\u001b[39mllm_int8_enable_fp32_cpu_offload\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/transformers/utils/import_utils.py:1354\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1354\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1355\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/FYP_Chatbot/test02/src/myenv-test002-03/lib/python3.9/site-packages/transformers/utils/import_utils.py:1366\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1367\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# Defining the name of the Falcon model\n",
    "model_name = \"ybelkada/falcon-7b-sharded-bf16\"\n",
    "\n",
    "# Configuring the BitsAndBytes quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "load_in_4bit=True,\n",
    "bnb_4bit_quant_type=\"nf4\",\n",
    "bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# Loading the Falcon model with quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "model_name,\n",
    "quantization_config=bnb_config,\n",
    "trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Disabling cache usage in the model configuration\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e126a0a-46ab-4e25-8335-cc4f4dfbd789",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3988573585.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python -m bitsandbytes\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22829811-9111-4a6a-950e-4ac4640e6622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca9699-3845-4924-a710-d9a30c8c8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer for the Falcon 7B model with remote code trust\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Set the padding token to be the same as the end-of-sequence token\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544aec53-5fde-4b9e-ae1f-c882eb9c51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary module for LoRA configuration\n",
    "from peft import LoraConfig\n",
    "\n",
    "# Define the parameters for LoRA configuration\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "# Create the LoRA configuration object\n",
    "peft_config = LoraConfig(\n",
    "lora_alpha=lora_alpha,\n",
    "lora_dropout=lora_dropout,\n",
    "r=lora_r,\n",
    "bias=\"none\",\n",
    "task_type=\"CAUSAL_LM\",\n",
    "target_modules=[\n",
    "\"query_key_value\",\n",
    "\"dense\",\n",
    "\"dense_h_to_4h\",\n",
    "\"dense_4h_to_h\",\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a3730-e0a5-4619-b32e-b137fdaafcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "# Define the directory to save training results\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Set the batch size per device during training\n",
    "per_device_train_batch_size = 2\n",
    "\n",
    "# Number of steps to accumulate gradients before updating the model\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# Choose the optimizer type (e.g., \"paged_adamw_32bit\")\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Interval to save model checkpoints (every 10 steps)\n",
    "save_steps = 10\n",
    "\n",
    "# Interval to log training metrics (every 10 steps)\n",
    "logging_steps = 10\n",
    "\n",
    "# Learning rate for optimization\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Maximum gradient norm for gradient clipping\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Maximum number of training steps\n",
    "max_steps = 50\n",
    "\n",
    "# Warmup ratio for learning rate scheduling\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Type of learning rate scheduler (e.g., \"constant\")\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Create a TrainingArguments object to configure the training process\n",
    "training_arguments = TrainingArguments(\n",
    "output_dir=output_dir,\n",
    "per_device_train_batch_size=per_device_train_batch_size,\n",
    "gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "optim=optim,\n",
    "save_steps=save_steps,\n",
    "logging_steps=logging_steps,\n",
    "learning_rate=learning_rate,\n",
    "fp16=True,  # Use mixed precision training (16-bit)\n",
    "max_grad_norm=max_grad_norm,\n",
    "max_steps=max_steps,\n",
    "warmup_ratio=warmup_ratio,\n",
    "group_by_length=True,\n",
    "lr_scheduler_type=lr_scheduler_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87cba87e-a67b-4a77-b1da-8db0da4db5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4180e7ab03ef4d3fb0f2e5142cc15c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Import the SFTTrainer from the TRL library\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Set the maximum sequence length\n",
    "max_seq_length = 200\n",
    "\n",
    "# Create a trainer instance using SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "model=model,\n",
    "train_dataset=dataset,\n",
    "peft_config=peft_config,\n",
    "dataset_text_field=\"text\",\n",
    "max_seq_length=max_seq_length,\n",
    "tokenizer=tokenizer,\n",
    "args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032c65f3-a07f-463d-a23a-c49e994bf61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd7e571-c64e-45f5-86ce-e1193ca40ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   5236 MiB |   5300 MiB |  19032 MiB |  13796 MiB |\n",
      "|       from large pool |   5219 MiB |   5283 MiB |  19015 MiB |  13796 MiB |\n",
      "|       from small pool |     17 MiB |     17 MiB |     17 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   5236 MiB |   5300 MiB |  19032 MiB |  13796 MiB |\n",
      "|       from large pool |   5219 MiB |   5283 MiB |  19015 MiB |  13796 MiB |\n",
      "|       from small pool |     17 MiB |     17 MiB |     17 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   5196 MiB |   5261 MiB |  18962 MiB |  13765 MiB |\n",
      "|       from large pool |   5179 MiB |   5245 MiB |  18944 MiB |  13765 MiB |\n",
      "|       from small pool |     17 MiB |     17 MiB |     17 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   5342 MiB |   5342 MiB |   6064 MiB | 739328 KiB |\n",
      "|       from large pool |   5324 MiB |   5324 MiB |   6046 MiB | 739328 KiB |\n",
      "|       from small pool |     18 MiB |     18 MiB |     18 MiB |      0 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 108220 KiB | 576705 KiB |   8480 MiB |   8374 MiB |\n",
      "|       from large pool | 107440 KiB | 575925 KiB |   8463 MiB |   8358 MiB |\n",
      "|       from small pool |    780 KiB |   2039 KiB |     16 MiB |     15 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     803    |     803    |     999    |     196    |\n",
      "|       from large pool |     513    |     513    |     643    |     130    |\n",
      "|       from small pool |     290    |     291    |     356    |      66    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     803    |     803    |     999    |     196    |\n",
      "|       from large pool |     513    |     513    |     643    |     130    |\n",
      "|       from small pool |     290    |     291    |     356    |      66    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      75    |      75    |      77    |       2    |\n",
      "|       from large pool |      66    |      67    |      68    |       2    |\n",
      "|       from small pool |       9    |       9    |       9    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       4    |      15    |     128    |     124    |\n",
      "|       from large pool |       1    |      13    |      86    |      85    |\n",
      "|       from small pool |       3    |       3    |      42    |      39    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c72d5da0-43e9-44b1-baf1-41be3d9d2cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmohamed-omar-farooq\u001b[0m (\u001b[33momars-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cv/FYP_ChatBot/test02/src/wandb/run-20240220_193144-e59u8okc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/omars-team/huggingface/runs/e59u8okc' target=\"_blank\">filigreed-firecracker-6</a></strong> to <a href='https://wandb.ai/omars-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/omars-team/huggingface' target=\"_blank\">https://wandb.ai/omars-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/omars-team/huggingface/runs/e59u8okc' target=\"_blank\">https://wandb.ai/omars-team/huggingface/runs/e59u8okc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 10:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.529200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.455600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.475800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.807600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-10 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-20 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-30 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-40 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-50 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=1.5643066024780274, metrics={'train_runtime': 620.1459, 'train_samples_per_second': 0.645, 'train_steps_per_second': 0.081, 'total_flos': 2859666679534080.0, 'train_loss': 1.5643066024780274, 'epoch': 0.04})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through the named modules of the trainer's model\n",
    "for name, module in trainer.model.named_modules():\n",
    "    # Check if the name contains \"norm\"\n",
    "    if \"norm\" in name:\n",
    "        # Convert the module to use torch.float32 data type\n",
    "        module = module.to(torch.float32)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8e077d-e226-49a3-bca5-1dce85849e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Token:  ········\n",
      "Add token as git credential? (Y/n)  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/cv/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c05885d-63b1-4a1a-a537-387c44b6607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d5eb9ec01a4634bd5486beb259d639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/522M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ad959e3aa94a2ea78fff1a6fe5af0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0493712a852463fadf0d778ff3375e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/omarfarooq908/results/commit/d3b4779ad9abcda464302916012d98fc7fa98d64', commit_message='omarfarooq908/falcon-7b-finetuned01', commit_description='', oid='d3b4779ad9abcda464302916012d98fc7fa98d64', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory where you want to save the fine-tuned model\n",
    "output_dir = \"./fine_tuned_model\"\n",
    "\n",
    "# Save the fine-tuned model using the save_model method\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "# Optionally, you can also upload the model to the Hugging Face model hub\n",
    "# if you want to share it with others\n",
    "trainer.push_to_hub(\"omarfarooq908/falcon-7b-finetuned01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b4b2c1-266d-41f6-860a-a1393596d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import move_repo\n",
    "move_repo(from_id=\"omarfarooq908/results\", to_id=\"omarfarooq908/falcon-7b-finetuned01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff6f84f-753a-40f4-8654-396fa63570e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save_model() got an unexpected keyword argument 'max_shard_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine_tuned_model01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model using the save_model method\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m100MB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Optionally, you can also upload the model to the Hugging Face model hub\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# if you want to share it with others\u001b[39;00m\n\u001b[1;32m      9\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124momarfarooq908/falcon-7b-finetuned01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: save_model() got an unexpected keyword argument 'max_shard_size'"
     ]
    }
   ],
   "source": [
    "# Define the directory where you want to save the fine-tuned model\n",
    "output_dir = \"./fine_tuned_model01-01\"\n",
    "\n",
    "# Save the fine-tuned model using the save_model method\n",
    "trainer.save_model(output_dir, max_shard_size=\"100MB\")\n",
    "\n",
    "# Optionally, you can also upload the model to the Hugging Face model hub\n",
    "# if you want to share it with others\n",
    "trainer.push_to_hub(\"omarfarooq908/falcon-7b-finetuned01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fcc42c-e155-44f5-8652-82f118d223b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 359 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/cv/FYP_ChatBot/test02/src/myenv-test002-02/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b389acaa-0fb2-491b-802d-71ad2b73afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "171d48ab-3573-44e5-8e73-16896f057c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d85fe47-6be6-485a-9088-e07aac249dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_File_Path = \"./fine_tuned_model01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdae8cae-9ef2-4621-bf75-f9799efe761b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SFTTrainer' object has no attribute 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_File_Path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0.1GB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/accelerate/accelerator.py:2562\u001b[0m, in \u001b[0;36mAccelerator.save_model\u001b[0;34m(self, model, save_directory, max_shard_size, safe_serialization)\u001b[0m\n\u001b[1;32m   2556\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_directory, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;66;03m# get the state_dict of the model\u001b[39;00m\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   2560\u001b[0m     [\n\u001b[1;32m   2561\u001b[0m         module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39moffload\n\u001b[0;32m-> 2562\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m()\n\u001b[1;32m   2563\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hf_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module\u001b[38;5;241m.\u001b[39m_hf_hook, AlignDevicesHook)\n\u001b[1;32m   2564\u001b[0m     ]\n\u001b[1;32m   2565\u001b[0m ):\n\u001b[1;32m   2566\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m get_state_dict_offloaded_model(model)\n\u001b[1;32m   2567\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SFTTrainer' object has no attribute 'modules'"
     ]
    }
   ],
   "source": [
    "accelerator.save_model(model=trainer, save_directory=model_File_Path, max_shard_size='0.1GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a192e6-c4d0-4d4e-b608-3d6d6cfab263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89bb824f-ab9b-420d-9ca0-1316ab18d628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp311-cp311-linux_x86_64.whl (819.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.2/819.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:05\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.2%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/cv/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/cv/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/cv/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/cv/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/cv/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/cv/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.19.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/cv/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/cv/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/cv/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/cv/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
      "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 torch-2.2.2+cu118 torchaudio-2.2.2+cu118 torchvision-0.17.2+cu118 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5700be60-d09b-4a80-882a-72328553e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AVG', 'AggregationType', 'AliasDb', 'Any', 'AnyType', 'Argument', 'ArgumentSpec', 'AwaitType', 'BFloat16Storage', 'BFloat16Tensor', 'BenchmarkConfig', 'BenchmarkExecutionStats', 'Block', 'BoolStorage', 'BoolTensor', 'BoolType', 'BufferDict', 'ByteStorage', 'ByteTensor', 'CallStack', 'Callable', 'Capsule', 'CharStorage', 'CharTensor', 'ClassType', 'Code', 'CompilationUnit', 'CompleteArgumentSpec', 'ComplexDoubleStorage', 'ComplexFloatStorage', 'ComplexType', 'ConcreteModuleType', 'ConcreteModuleTypeBuilder', 'DeepCopyMemoTable', 'DeserializationStorageContext', 'DeviceObjType', 'Dict', 'DictType', 'DisableTorchFunction', 'DisableTorchFunctionSubclass', 'DispatchKey', 'DispatchKeySet', 'DoubleStorage', 'DoubleTensor', 'EnumType', 'ErrorReport', 'ExcludeDispatchKeyGuard', 'ExecutionPlan', 'FatalError', 'FileCheck', 'FloatStorage', 'FloatTensor', 'FloatType', 'FunctionSchema', 'Future', 'FutureType', 'Generator', 'Gradient', 'Graph', 'GraphExecutorState', 'HalfStorage', 'HalfTensor', 'IODescriptor', 'InferredType', 'IntStorage', 'IntTensor', 'IntType', 'InterfaceType', 'JITException', 'List', 'ListType', 'LiteScriptModule', 'LockingLogger', 'LoggerBase', 'LongStorage', 'LongTensor', 'ModuleDict', 'Node', 'NoneType', 'NoopLogger', 'NumberType', 'OperatorInfo', 'Optional', 'OptionalType', 'PRIVATE_OPS', 'ParameterDict', 'PyObjectType', 'PyTorchFileReader', 'PyTorchFileWriter', 'QInt32Storage', 'QInt8Storage', 'QUInt2x4Storage', 'QUInt4x2Storage', 'QUInt8Storage', 'RRefType', 'SUM', 'ScriptClass', 'ScriptClassFunction', 'ScriptDict', 'ScriptDictIterator', 'ScriptDictKeyIterator', 'ScriptFunction', 'ScriptList', 'ScriptListIterator', 'ScriptMethod', 'ScriptModule', 'ScriptModuleSerializer', 'ScriptObject', 'ScriptObjectProperty', 'SerializationStorageContext', 'Set', 'ShortStorage', 'ShortTensor', 'Size', 'StaticModule', 'Storage', 'StorageBase', 'Stream', 'StreamObjType', 'StringType', 'SymBool', 'SymBoolType', 'SymFloat', 'SymInt', 'SymIntType', 'TYPE_CHECKING', 'Tag', 'Tensor', 'TensorType', 'ThroughputBenchmark', 'TracingState', 'Tuple', 'TupleType', 'Type', 'TypedStorage', 'USE_GLOBAL_DEPS', 'USE_RTLD_GLOBAL_WITH_LIBTORCH', 'Union', 'UnionType', 'UntypedStorage', 'Use', 'Value', '_C', '_GLOBAL_DEVICE_CONTEXT', '_TorchCompileInductorWrapper', '_TorchCompileWrapper', '_TritonLibrary', '_VF', '__all__', '__annotations__', '__builtins__', '__cached__', '__config__', '__doc__', '__file__', '__future__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_adaptive_avg_pool2d', '_adaptive_avg_pool3d', '_add_batch_dim', '_add_relu', '_add_relu_', '_addmm_activation', '_aminmax', '_amp_foreach_non_finite_check_and_unscale_', '_amp_update_scale_', '_assert', '_assert_async', '_assert_tensor_metadata', '_awaits', '_batch_norm_impl_index', '_cast_Byte', '_cast_Char', '_cast_Double', '_cast_Float', '_cast_Half', '_cast_Int', '_cast_Long', '_cast_Short', '_check', '_check_index', '_check_is_size', '_check_not_implemented', '_check_tensor_all', '_check_tensor_all_with', '_check_type', '_check_value', '_check_with', '_choose_qparams_per_tensor', '_classes', '_coalesce', '_compile', '_compute_linear_combination', '_conj', '_conj_copy', '_conj_physical', '_constrain_as_size', '_constrain_as_value', '_convert_indices_from_coo_to_csr', '_convert_indices_from_csr_to_coo', '_convert_weight_to_int4pack', '_convolution', '_convolution_mode', '_copy_from', '_copy_from_and_resize', '_cslt_compress', '_cslt_sparse_mm', '_ctc_loss', '_cudnn_ctc_loss', '_cudnn_init_dropout_state', '_cudnn_rnn', '_cudnn_rnn_flatten_weight', '_cufft_clear_plan_cache', '_cufft_get_plan_cache_max_size', '_cufft_get_plan_cache_size', '_cufft_set_plan_cache_max_size', '_cummax_helper', '_cummin_helper', '_custom_op', '_debug_has_internal_overlap', '_decomp', '_deprecated_attrs', '_dim_arange', '_dirichlet_grad', '_disable_dynamo', '_disable_functionalization', '_dispatch', '_efficientzerotensor', '_embedding_bag', '_embedding_bag_forward_only', '_empty_affine_quantized', '_empty_per_channel_affine_quantized', '_enable_functionalization', '_euclidean_dist', '_fake_quantize_learnable_per_channel_affine', '_fake_quantize_learnable_per_tensor_affine', '_fake_quantize_per_tensor_affine_cachemask_tensor_qparams', '_fft_c2c', '_fft_c2r', '_fft_r2c', '_fill_mem_eff_dropout_mask_', '_foobar', '_foreach_abs', '_foreach_abs_', '_foreach_acos', '_foreach_acos_', '_foreach_add', '_foreach_add_', '_foreach_addcdiv', '_foreach_addcdiv_', '_foreach_addcmul', '_foreach_addcmul_', '_foreach_asin', '_foreach_asin_', '_foreach_atan', '_foreach_atan_', '_foreach_ceil', '_foreach_ceil_', '_foreach_clamp_max', '_foreach_clamp_max_', '_foreach_clamp_min', '_foreach_clamp_min_', '_foreach_copy_', '_foreach_cos', '_foreach_cos_', '_foreach_cosh', '_foreach_cosh_', '_foreach_div', '_foreach_div_', '_foreach_erf', '_foreach_erf_', '_foreach_erfc', '_foreach_erfc_', '_foreach_exp', '_foreach_exp_', '_foreach_expm1', '_foreach_expm1_', '_foreach_floor', '_foreach_floor_', '_foreach_frac', '_foreach_frac_', '_foreach_lerp', '_foreach_lerp_', '_foreach_lgamma', '_foreach_lgamma_', '_foreach_log', '_foreach_log10', '_foreach_log10_', '_foreach_log1p', '_foreach_log1p_', '_foreach_log2', '_foreach_log2_', '_foreach_log_', '_foreach_maximum', '_foreach_maximum_', '_foreach_minimum', '_foreach_minimum_', '_foreach_mul', '_foreach_mul_', '_foreach_neg', '_foreach_neg_', '_foreach_norm', '_foreach_pow', '_foreach_pow_', '_foreach_reciprocal', '_foreach_reciprocal_', '_foreach_round', '_foreach_round_', '_foreach_sigmoid', '_foreach_sigmoid_', '_foreach_sign', '_foreach_sign_', '_foreach_sin', '_foreach_sin_', '_foreach_sinh', '_foreach_sinh_', '_foreach_sqrt', '_foreach_sqrt_', '_foreach_sub', '_foreach_sub_', '_foreach_tan', '_foreach_tan_', '_foreach_tanh', '_foreach_tanh_', '_foreach_trunc', '_foreach_trunc_', '_foreach_zero_', '_freeze_functional_tensor', '_from_functional_tensor', '_functional_assert_async', '_functional_sym_constrain_range', '_functional_sym_constrain_range_for_size', '_functionalize_are_all_mutations_hidden_from_autograd', '_functionalize_are_all_mutations_under_no_grad_or_inference_mode', '_functionalize_commit_update', '_functionalize_enable_reapply_views', '_functionalize_has_data_mutation', '_functionalize_has_metadata_mutation', '_functionalize_is_multi_output_view', '_functionalize_mark_mutation_hidden_from_autograd', '_functionalize_replace', '_functionalize_sync', '_functionalize_was_storage_changed', '_functorch', '_fused_adam_', '_fused_adamw_', '_fused_dropout', '_fused_moving_avg_obs_fq_helper', '_fused_sdp_choice', '_fw_primal_copy', '_grid_sampler_2d_cpu_fallback', '_guards', '_has_compatible_shallow_copy_type', '_higher_order_ops', '_histogramdd_bin_edges', '_histogramdd_from_bin_cts', '_histogramdd_from_bin_tensors', '_import_dotted_name', '_index_put_impl_', '_indices_copy', '_initExtension', '_int_mm', '_is_all_true', '_is_any_true', '_is_functional_tensor', '_is_zerotensor', '_jit_internal', '_lazy_modules', '_library', '_linalg_check_errors', '_linalg_det', '_linalg_eigh', '_linalg_slogdet', '_linalg_solve_ex', '_linalg_svd', '_linalg_utils', '_load_global_deps', '_lobpcg', '_log_softmax', '_log_softmax_backward_data', '_logcumsumexp', '_logging', '_lowrank', '_lstm_mps', '_lu_with_info', '_make_dep_token', '_make_dual', '_make_dual_copy', '_make_per_channel_quantized_tensor', '_make_per_tensor_quantized_tensor', '_masked_scale', '_masked_softmax', '_meta_registrations', '_mirror_autograd_meta_to', '_mixed_dtypes_linear', '_mkldnn', '_mkldnn_reshape', '_mkldnn_transpose', '_mkldnn_transpose_', '_mps_convolution', '_mps_convolution_transpose', '_namedtensor_internals', '_native_batch_norm_legit', '_native_batch_norm_legit_no_training', '_native_multi_head_attention', '_neg_view', '_neg_view_copy', '_nested_from_padded', '_nested_from_padded_and_nested_example', '_nested_tensor_from_mask', '_nested_tensor_from_mask_left_aligned', '_nested_tensor_from_tensor_list', '_nested_tensor_softmax_with_shape', '_nested_view_from_buffer', '_nested_view_from_buffer_copy', '_nnpack_available', '_nnpack_spatial_convolution', '_ops', '_pack_padded_sequence', '_pad_packed_sequence', '_pin_memory', '_preload_cuda_deps', '_prelu_kernel', '_prims', '_prims_common', '_propagate_xla_data', '_refs', '_register_device_module', '_remove_batch_dim', '_reshape_alias_copy', '_reshape_from_tensor', '_resize_output_', '_rowwise_prune', '_running_with_deploy', '_sample_dirichlet', '_saturate_weight_to_fp16', '_scaled_dot_product_attention_math', '_scaled_dot_product_efficient_attention', '_scaled_dot_product_flash_attention', '_scaled_mm', '_segment_reduce', '_shape_as_tensor', '_sobol_engine_draw', '_sobol_engine_ff_', '_sobol_engine_initialize_state_', '_sobol_engine_scramble_', '_softmax', '_softmax_backward_data', '_sources', '_sparse_broadcast_to', '_sparse_broadcast_to_copy', '_sparse_coo_tensor_unsafe', '_sparse_csr_prod', '_sparse_csr_sum', '_sparse_log_softmax_backward_data', '_sparse_semi_structured_linear', '_sparse_softmax_backward_data', '_sparse_sparse_matmul', '_sparse_sum', '_stack', '_standard_gamma', '_standard_gamma_grad', '_storage_classes', '_streambase', '_subclasses', '_sync', '_tensor', '_tensor_classes', '_tensor_str', '_test_autograd_multiple_dispatch', '_test_autograd_multiple_dispatch_view', '_test_autograd_multiple_dispatch_view_copy', '_test_check_tensor', '_test_functorch_fallback', '_test_serialization_subcmul', '_to_cpu', '_to_functional_tensor', '_to_sparse_semi_structured', '_transform_bias_rescale_qkv', '_transformer_encoder_layer_fwd', '_trilinear', '_triton_multi_head_attention', '_triton_scaled_dot_attention', '_unique', '_unique2', '_unpack_dual', '_unsafe_index', '_unsafe_index_put', '_use_cudnn_ctc_loss', '_use_cudnn_rnn_flatten_weight', '_utils', '_utils_internal', '_validate_compressed_sparse_indices', '_validate_sparse_bsc_tensor_args', '_validate_sparse_bsr_tensor_args', '_validate_sparse_compressed_tensor_args', '_validate_sparse_coo_tensor_args', '_validate_sparse_csc_tensor_args', '_validate_sparse_csr_tensor_args', '_values_copy', '_vendor', '_vmap_internals', '_warn_typed_storage_removal', '_weight_int4pack_mm', '_weight_norm', '_weight_norm_interface', '_weights_only_unpickler', 'abs', 'abs_', 'absolute', 'acos', 'acos_', 'acosh', 'acosh_', 'adaptive_avg_pool1d', 'adaptive_max_pool1d', 'add', 'addbmm', 'addcdiv', 'addcmul', 'addmm', 'addmv', 'addmv_', 'addr', 'adjoint', 'affine_grid_generator', 'alias_copy', 'align_tensors', 'all', 'allclose', 'alpha_dropout', 'alpha_dropout_', 'amax', 'amin', 'aminmax', 'amp', 'angle', 'any', 'ao', 'arange', 'arccos', 'arccos_', 'arccosh', 'arccosh_', 'arcsin', 'arcsin_', 'arcsinh', 'arcsinh_', 'arctan', 'arctan2', 'arctan_', 'arctanh', 'arctanh_', 'are_deterministic_algorithms_enabled', 'argmax', 'argmin', 'argsort', 'argwhere', 'as_strided', 'as_strided_', 'as_strided_copy', 'as_strided_scatter', 'as_tensor', 'asarray', 'asin', 'asin_', 'asinh', 'asinh_', 'atan', 'atan2', 'atan_', 'atanh', 'atanh_', 'atleast_1d', 'atleast_2d', 'atleast_3d', 'attr', 'autocast', 'autocast_decrement_nesting', 'autocast_increment_nesting', 'autograd', 'avg_pool1d', 'backends', 'baddbmm', 'bartlett_window', 'batch_norm', 'batch_norm_backward_elemt', 'batch_norm_backward_reduce', 'batch_norm_elemt', 'batch_norm_gather_stats', 'batch_norm_gather_stats_with_counts', 'batch_norm_stats', 'batch_norm_update_stats', 'bernoulli', 'bfloat16', 'bilinear', 'binary_cross_entropy_with_logits', 'bincount', 'binomial', 'bits16', 'bits1x8', 'bits2x4', 'bits4x2', 'bits8', 'bitwise_and', 'bitwise_left_shift', 'bitwise_not', 'bitwise_or', 'bitwise_right_shift', 'bitwise_xor', 'blackman_window', 'block_diag', 'bmm', 'bool', 'broadcast_shapes', 'broadcast_tensors', 'broadcast_to', 'bucketize', 'builtins', 'can_cast', 'candidate', 'cartesian_prod', 'cat', 'ccol_indices_copy', 'cdist', 'cdouble', 'ceil', 'ceil_', 'celu', 'celu_', 'cfloat', 'chain_matmul', 'chalf', 'channel_shuffle', 'channels_last', 'channels_last_3d', 'cholesky', 'cholesky_inverse', 'cholesky_solve', 'choose_qparams_optimized', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'classes', 'classproperty', 'clear_autocast_cache', 'clip', 'clip_', 'clone', 'col_indices_copy', 'column_stack', 'combinations', 'compile', 'compiled_with_cxx11_abi', 'compiler', 'complex', 'complex128', 'complex32', 'complex64', 'concat', 'concatenate', 'cond', 'conj', 'conj_physical', 'conj_physical_', 'constant_pad_nd', 'contiguous_format', 'conv1d', 'conv2d', 'conv3d', 'conv_tbc', 'conv_transpose1d', 'conv_transpose2d', 'conv_transpose3d', 'convolution', 'copysign', 'corrcoef', 'cos', 'cos_', 'cosh', 'cosh_', 'cosine_embedding_loss', 'cosine_similarity', 'count_nonzero', 'cov', 'cpp', 'cpu', 'cross', 'crow_indices_copy', 'ctc_loss', 'ctypes', 'cuda', 'cudnn_affine_grid_generator', 'cudnn_batch_norm', 'cudnn_convolution', 'cudnn_convolution_add_relu', 'cudnn_convolution_relu', 'cudnn_convolution_transpose', 'cudnn_grid_sampler', 'cudnn_is_acceptable', 'cummax', 'cummin', 'cumprod', 'cumsum', 'cumulative_trapezoid', 'default_generator', 'deg2rad', 'deg2rad_', 'dequantize', 'det', 'detach', 'detach_', 'detach_copy', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'diagonal_copy', 'diagonal_scatter', 'diff', 'digamma', 'dist', 'distributed', 'distributions', 'div', 'divide', 'dot', 'double', 'dropout', 'dropout_', 'dsmm', 'dsplit', 'dstack', 'dtype', 'e', 'eig', 'einsum', 'embedding', 'embedding_bag', 'embedding_renorm_', 'empty', 'empty_like', 'empty_permuted', 'empty_quantized', 'empty_strided', 'enable_grad', 'eq', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'exp', 'exp2', 'exp2_', 'exp_', 'expand_copy', 'expm1', 'expm1_', 'export', 'eye', 'fake_quantize_per_channel_affine', 'fake_quantize_per_tensor_affine', 'fbgemm_linear_fp16_weight', 'fbgemm_linear_fp16_weight_fp32_activation', 'fbgemm_linear_int8_weight', 'fbgemm_linear_int8_weight_fp32_activation', 'fbgemm_linear_quantize_weight', 'fbgemm_pack_gemm_matrix_fp16', 'fbgemm_pack_quantized_matrix', 'feature_alpha_dropout', 'feature_alpha_dropout_', 'feature_dropout', 'feature_dropout_', 'fft', 'fill', 'fill_', 'finfo', 'fix', 'fix_', 'flatten', 'flip', 'fliplr', 'flipud', 'float', 'float16', 'float32', 'float64', 'float8_e4m3fn', 'float8_e4m3fnuz', 'float8_e5m2', 'float8_e5m2fnuz', 'float_power', 'floor', 'floor_', 'floor_divide', 'fmax', 'fmin', 'fmod', 'fork', 'frac', 'frac_', 'frexp', 'frobenius_norm', 'from_dlpack', 'from_file', 'from_numpy', 'frombuffer', 'full', 'full_like', 'func', 'functional', 'fused_moving_avg_obs_fake_quant', 'futures', 'fx', 'gather', 'gcd', 'gcd_', 'ge', 'geqrf', 'ger', 'get_autocast_cpu_dtype', 'get_autocast_gpu_dtype', 'get_autocast_ipu_dtype', 'get_autocast_xla_dtype', 'get_default_dtype', 'get_deterministic_debug_mode', 'get_device', 'get_file_path', 'get_float32_matmul_precision', 'get_num_interop_threads', 'get_num_threads', 'get_rng_state', 'gradient', 'greater', 'greater_equal', 'grid_sampler', 'grid_sampler_2d', 'grid_sampler_3d', 'group_norm', 'gru', 'gru_cell', 'gt', 'half', 'hamming_window', 'hann_window', 'hardshrink', 'has_lapack', 'has_mkl', 'has_openmp', 'has_spectral', 'heaviside', 'hinge_embedding_loss', 'histc', 'histogram', 'histogramdd', 'hsmm', 'hsplit', 'hspmm', 'hstack', 'hub', 'hypot', 'i0', 'i0_', 'igamma', 'igammac', 'iinfo', 'imag', 'import_ir_module', 'import_ir_module_from_buffer', 'index_add', 'index_copy', 'index_fill', 'index_put', 'index_put_', 'index_reduce', 'index_select', 'indices_copy', 'inf', 'inference_mode', 'init_num_threads', 'initial_seed', 'inner', 'inspect', 'instance_norm', 'int', 'int16', 'int32', 'int64', 'int8', 'int_repr', 'inverse', 'is_anomaly_check_nan_enabled', 'is_anomaly_enabled', 'is_autocast_cache_enabled', 'is_autocast_cpu_enabled', 'is_autocast_enabled', 'is_autocast_ipu_enabled', 'is_autocast_xla_enabled', 'is_complex', 'is_conj', 'is_deterministic_algorithms_warn_only_enabled', 'is_distributed', 'is_floating_point', 'is_grad_enabled', 'is_inference', 'is_inference_mode_enabled', 'is_neg', 'is_nonzero', 'is_same_size', 'is_signed', 'is_storage', 'is_tensor', 'is_vulkan_available', 'is_warn_always_enabled', 'isclose', 'isfinite', 'isin', 'isinf', 'isnan', 'isneginf', 'isposinf', 'isreal', 'istft', 'jagged', 'jit', 'kaiser_window', 'kl_div', 'kron', 'kthvalue', 'layer_norm', 'layout', 'lcm', 'lcm_', 'ldexp', 'ldexp_', 'le', 'legacy_contiguous_format', 'lerp', 'less', 'less_equal', 'lgamma', 'library', 'linalg', 'linspace', 'load', 'lobpcg', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_softmax', 'logaddexp', 'logaddexp2', 'logcumsumexp', 'logdet', 'logical_and', 'logical_not', 'logical_or', 'logical_xor', 'logit', 'logit_', 'logspace', 'logsumexp', 'long', 'lstm', 'lstm_cell', 'lstsq', 'lt', 'lu', 'lu_solve', 'lu_unpack', 'manual_seed', 'margin_ranking_loss', 'masked', 'masked_fill', 'masked_scatter', 'masked_select', 'math', 'matmul', 'matrix_exp', 'matrix_power', 'matrix_rank', 'max', 'max_pool1d', 'max_pool1d_with_indices', 'max_pool2d', 'max_pool3d', 'maximum', 'mean', 'median', 'memory_format', 'merge_type_from_type_comment', 'meshgrid', 'min', 'minimum', 'miopen_batch_norm', 'miopen_convolution', 'miopen_convolution_add_relu', 'miopen_convolution_relu', 'miopen_convolution_transpose', 'miopen_depthwise_convolution', 'miopen_rnn', 'mkldnn_adaptive_avg_pool2d', 'mkldnn_convolution', 'mkldnn_linear_backward_weights', 'mkldnn_max_pool2d', 'mkldnn_max_pool3d', 'mkldnn_rnn_layer', 'mm', 'mode', 'moveaxis', 'movedim', 'mps', 'msort', 'mul', 'multinomial', 'multiply', 'multiprocessing', 'mv', 'mvlgamma', 'name', 'nan', 'nan_to_num', 'nan_to_num_', 'nanmean', 'nanmedian', 'nanquantile', 'nansum', 'narrow', 'narrow_copy', 'native_batch_norm', 'native_channel_shuffle', 'native_dropout', 'native_group_norm', 'native_layer_norm', 'native_norm', 'ne', 'neg', 'neg_', 'negative', 'negative_', 'nested', 'nextafter', 'nn', 'no_grad', 'nonzero', 'nonzero_static', 'norm', 'norm_except_dim', 'normal', 'not_equal', 'nuclear_norm', 'numel', 'obj', 'ones', 'ones_like', 'ops', 'optim', 'orgqr', 'ormqr', 'os', 'outer', 'overrides', 'package', 'pairwise_distance', 'parse_ir', 'parse_schema', 'parse_type_comment', 'pca_lowrank', 'pdist', 'per_channel_affine', 'per_channel_affine_float_qparams', 'per_channel_symmetric', 'per_tensor_affine', 'per_tensor_symmetric', 'permute', 'permute_copy', 'pi', 'pinverse', 'pixel_shuffle', 'pixel_unshuffle', 'platform', 'poisson', 'poisson_nll_loss', 'polar', 'polygamma', 'positive', 'pow', 'prelu', 'prepare_multiprocessing_environment', 'preserve_format', 'prod', 'profiler', 'promote_types', 'put', 'py_float', 'py_int', 'q_per_channel_axis', 'q_per_channel_scales', 'q_per_channel_zero_points', 'q_scale', 'q_zero_point', 'qint32', 'qint8', 'qr', 'qscheme', 'quantile', 'quantization', 'quantize_per_channel', 'quantize_per_tensor', 'quantize_per_tensor_dynamic', 'quantized_batch_norm', 'quantized_gru', 'quantized_gru_cell', 'quantized_lstm', 'quantized_lstm_cell', 'quantized_max_pool1d', 'quantized_max_pool2d', 'quantized_max_pool3d', 'quantized_rnn_relu_cell', 'quantized_rnn_tanh_cell', 'quasirandom', 'quint2x4', 'quint4x2', 'quint8', 'rad2deg', 'rad2deg_', 'rand', 'rand_like', 'randint', 'randint_like', 'randn', 'randn_like', 'random', 'randperm', 'range', 'ravel', 'read_vitals', 'real', 'reciprocal', 'reciprocal_', 'relu', 'relu_', 'remainder', 'renorm', 'repeat_interleave', 'reshape', 'resize_as_', 'resize_as_sparse_', 'resolve_conj', 'resolve_neg', 'result_type', 'return_types', 'rnn_relu', 'rnn_relu_cell', 'rnn_tanh', 'rnn_tanh_cell', 'roll', 'rot90', 'round', 'round_', 'row_indices_copy', 'row_stack', 'rrelu', 'rrelu_', 'rsqrt', 'rsqrt_', 'rsub', 'saddmm', 'save', 'scalar_tensor', 'scatter', 'scatter_add', 'scatter_reduce', 'searchsorted', 'seed', 'segment_reduce', 'select', 'select_copy', 'select_scatter', 'selu', 'selu_', 'serialization', 'set_anomaly_enabled', 'set_autocast_cache_enabled', 'set_autocast_cpu_dtype', 'set_autocast_cpu_enabled', 'set_autocast_enabled', 'set_autocast_gpu_dtype', 'set_autocast_ipu_dtype', 'set_autocast_ipu_enabled', 'set_autocast_xla_dtype', 'set_autocast_xla_enabled', 'set_default_device', 'set_default_dtype', 'set_default_tensor_type', 'set_deterministic_debug_mode', 'set_float32_matmul_precision', 'set_flush_denormal', 'set_grad_enabled', 'set_num_interop_threads', 'set_num_threads', 'set_printoptions', 'set_rng_state', 'set_vital', 'set_warn_always', 'sgn', 'short', 'sigmoid', 'sigmoid_', 'sign', 'signal', 'signbit', 'sin', 'sin_', 'sinc', 'sinc_', 'sinh', 'sinh_', 'slice_copy', 'slice_scatter', 'slogdet', 'smm', 'softmax', 'solve', 'sort', 'sparse', 'sparse_bsc', 'sparse_bsc_tensor', 'sparse_bsr', 'sparse_bsr_tensor', 'sparse_compressed_tensor', 'sparse_coo', 'sparse_coo_tensor', 'sparse_csc', 'sparse_csc_tensor', 'sparse_csr', 'sparse_csr_tensor', 'special', 'split', 'split_copy', 'split_with_sizes', 'split_with_sizes_copy', 'spmm', 'sqrt', 'sqrt_', 'square', 'square_', 'squeeze', 'squeeze_copy', 'sspaddmm', 'stack', 'std', 'std_mean', 'stft', 'storage', 'strided', 'sub', 'subtract', 'sum', 'svd', 'svd_lowrank', 'swapaxes', 'swapdims', 'sym_constrain_range', 'sym_constrain_range_for_size', 'sym_float', 'sym_int', 'sym_ite', 'sym_max', 'sym_min', 'sym_not', 'sym_sqrt', 'symeig', 'sys', 't', 't_copy', 'take', 'take_along_dim', 'tan', 'tan_', 'tanh', 'tanh_', 'tensor', 'tensor_split', 'tensordot', 'testing', 'textwrap', 'threshold', 'threshold_', 'tile', 'to_dlpack', 'topk', 'torch', 'torch_version', 'trace', 'transpose', 'transpose_copy', 'trapezoid', 'trapz', 'triangular_solve', 'tril', 'tril_indices', 'triplet_margin_loss', 'triu', 'triu_indices', 'true_divide', 'trunc', 'trunc_', 'typename', 'types', 'uint8', 'unbind', 'unbind_copy', 'unflatten', 'unfold_copy', 'unify_type_list', 'unique', 'unique_consecutive', 'unravel_index', 'unsafe_chunk', 'unsafe_split', 'unsafe_split_with_sizes', 'unsqueeze', 'unsqueeze_copy', 'use_deterministic_algorithms', 'utils', 'values_copy', 'vander', 'var', 'var_mean', 'vdot', 'version', 'view_as_complex', 'view_as_complex_copy', 'view_as_real', 'view_as_real_copy', 'view_copy', 'vitals_enabled', 'vmap', 'vsplit', 'vstack', 'wait', 'where', 'windows', 'xlogy', 'xlogy_', 'zero_', 'zeros', 'zeros_like']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(dir(torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765d55cf-b2b8-46f0-96e5-0fe1999d072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0538, 0.1905, 0.7190],\n",
      "        [0.8130, 0.9224, 0.8427],\n",
      "        [0.7393, 0.2891, 0.0696],\n",
      "        [0.6927, 0.5944, 0.0232],\n",
      "        [0.8149, 0.4556, 0.7563]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92536821-294e-449f-9c47-5a20779883b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2706a0-cfb0-40fc-9867-cf3211dde85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pdfplumber\n",
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c6376-8a45-4c65-adfb-d6f7d92205e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pdfplumber\n",
    "\n",
    "text = ''\n",
    "# Open the PDF file\n",
    "with pdfplumber.open('Capital-Volume-I.pdf') as pdf:\n",
    "    # Loop through each page and extract text\n",
    "    for page in pdf.pages:\n",
    "        text = text + page.extract_text()\n",
    "#        print(text)\n",
    "print(text[0])\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "text = text_splitter.create_documents([text])\n",
    "\n",
    "print(f'\\n First chunk : {text[0]}\\n')\n",
    "print(f'\\n Second chunk : {text[1]}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-test002-03",
   "language": "python",
   "name": "myenv-test002-03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
